{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "import random\n",
    "\n",
    "# Visualisation libraries\n",
    "\n",
    "## Text\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "# Visualisation libraries\n",
    "\n",
    "## Text\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font size=\"+2\"><b>\n",
    "Movie Reviews Comments classifications using Natural Language Toolkit    \n",
    "</b></font>\n",
    "<hr>\n",
    "<font size=\"+1\"><b>\n",
    "Naive Bayes Classifier (Improved Model)\n",
    "</b></font>\n",
    "</div>\n",
    "\n",
    "\n",
    "The Natural Language Toolkit, or more commonly [NLTK](https://www.nltk.org/), is a suite of libraries and programs for symbolic and statistical natural language processing for English written in the Python programming language.\n",
    "\n",
    "NLTK has a great library of datasets. Here we use, **Sentiment Polarity Dataset Version 2.0**. This can be downloaded using\n",
    "\n",
    "```Python\n",
    "nltk.download(\"movie_reviews\")\n",
    "from nltk.corpus import movie_reviews\n",
    "```\n",
    "\n",
    "Alternatively, we could download the dataset from the [GitHub repository](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/movie_reviews.zip).\n",
    "\n",
    "This dataset contains 1000 positive and 1000 negative processed reviews. Introduced in Pang/Lee ACL 2004. Released in June 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive Comments</th>\n",
       "      <th>Negative Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Shape</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Positive Comments  Negative Comments\n",
       "Shape               1000               1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[22mNumber of Words\u001b[0m = 1583820\n",
      "\u001b[40m\u001b[32m\u001b[22mPositive Comments:\u001b[0m\u001b[34m\u001b[22m =====================================================================================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pos/cv000_29590.txt',\n",
       " 'pos/cv001_18431.txt',\n",
       " 'pos/cv002_15918.txt',\n",
       " 'pos/cv003_11664.txt',\n",
       " 'pos/cv004_11636.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32m\u001b[22mNegative Comments:\u001b[0m\u001b[34m\u001b[22m =====================================================================================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[22m========================================================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "display(pd.DataFrame({'Positive Comments': [len(movie_reviews.fileids('pos'))],\n",
    "              'Negative Comments': [len(movie_reviews.fileids('neg'))]}, index = ['Shape']))\n",
    "\n",
    "print(Fore.GREEN + Style.NORMAL + 'Number of Words' + Style.RESET_ALL + ' = %i' % len(movie_reviews.words()))\n",
    "\n",
    "def Line(N): return N*'='\n",
    "print(Back.BLACK + Fore.GREEN + Style.NORMAL + 'Positive Comments:' +\n",
    "      Style.RESET_ALL + Fore.BLUE + Style.NORMAL + ' %s' % Line(120- len('Positive Comments:') - 1) + Style.RESET_ALL)\n",
    "display(movie_reviews.fileids('pos')[:5])\n",
    "print(Back.BLACK + Fore.GREEN + Style.NORMAL + 'Negative Comments:' +\n",
    "      Style.RESET_ALL + Fore.BLUE + Style.NORMAL + ' %s' % Line(120- len('Negative Comments:') - 1) + Style.RESET_ALL)\n",
    "display(movie_reviews.fileids('neg')[:5])\n",
    "print(Fore.BLUE + Style.NORMAL + '%s' % Line(120) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32m\u001b[22mA Random Positive Comment:\u001b[0m\u001b[34m\u001b[22m =============================================================================================\u001b[0m\n",
      "before you read my review , you gotta know that i love woody allen . \n",
      "this is a very important note because allen's films are generally an acquired taste and definitely not for everyone . \n",
      "i know folks who believe him to be a complete genius , while others see him as a dirty ol' schnook who keeps making the same movie over and over again . \n",
      "i love most of his films , but will admit to having been quite disappointed by his recent crop during the 90s . \n",
      "in fact , why he felt the need to make 10 movies in those 10 years is beyond me ! \n",
      "if you look at the quality of those films , you'll hear what i'm saying . \n",
      "the only two films of his that i really liked during that time were bullets over broadway and husbands and wives . \n",
      "in fact , i secretly hoped that he would take some \" time off \" at the turn of the millennium , just to re-energize or something , but it doesn't appear as though he has any intention of doing that . \n",
      "so here i am again , reviewing yet another woody allen movie and hoping that it brings back the woody from the days of old . \n",
      "plot : the year is 1940 and woody allen is a top-notch insurance investigator . \n",
      "his methods are very old-fashioned and apparently out of date . \n",
      "a new employee ( hunt ) has just been hired to streamline the operations for greater efficiency . \n",
      "the two do not like each other . \n",
      "one night , they are both put under a hypnotic trance by a magician , and unbeknownst to them , placed under his control . \n",
      "soon thereafter , jewels are stolen , words of love are exchanged and everyone is looking for an answer . \n",
      "critique : a wonderful recreation of the 1940s style movies , with the fast-talking witty banter between co-workers , a catchy jazz score moving things along , film noirish elements such as the veronica lake-type sexpot , one-liners galore and a fluffy , if inconsequential plotline . \n",
      "on the downside , the film actually starts off pretty slowly , with the first hour tossing only a few guffaws out there , but never really generating any kind of steady flow or energy . \n",
      "the sets , on the other hand , were amazing , the production design and costumes were perfect , and the casting ideal , so i kept hoping that the film would pick up and not turn into yet another mediocre outing for the man . \n",
      "but it wasn't not long before i was fully engaged by the characters , entertained by the many zingers delivered back-and-forth between allen and hunt , and actually interested in the resolution of the flick . \n",
      "i also appreciated how allen played the fine line between homage to the films of old , parody and actual reinvention ( note theron's entire female persona that is drenched in film noir- very cool ) . \n",
      "of course , films like this ( with little or no real tension in the plot ) need solid actors to keep you interested in the quick-fire dialogue , and once again , allen does a great job in playing his character , who for once , isn't his typical new york jewish neurotic cheating insecure husband dude . \n",
      "he actually plays a \" macho \" guy here and handles it pretty well , especially the scenes in which he's hypnotized . \n",
      "but the bigger surprise for me in this film was helen hunt , an actress who i was openly \" sick of seeing \" in movies late last year ( sorry babe , you were just in too many at the same time ! ) . \n",
      "anyway , she's really great in this film as the headstrong woman looking to a new era of equality amongst men , and doesn't miss a beat of allen's fast-paced dialogue . \n",
      "i didn't care much for her running joke about him \" dying \" whenever he left a room , but overall she was really good and i especially liked the way that her sweaters clung to her breasts as they did . . . yum , \n",
      "yum ! \n",
      "harumph , but i digress . \n",
      "so let's recap . \n",
      "a great looking picture with a nice jazzy score , some funny one-liners , especially in the second half , a decent plotline , although you shouldn't expect a real mystery or anything , and some solid acting all around . \n",
      "i can't say that this is even remotely close to any of allen's best work , but i certainly believe it to be a step in the right direction , especially after the dinky decade of films that he just went through . \n",
      "it's probably better geared towards allen fans more than anyone else , but i would still recommend this film to anyone looking for a cute , \" old-school \" kind of vibe , with chemistry between the leads , zippy dialogue and a satisfying conclusion . \n",
      "little known facts about this film and its stars : annie hall ( 10/10 ) - celebrity ( 5/10 ) - everyone says i love you ( 5/10 ) - husbands and wives ( 9/10 ) - mighty aphrodite ( 5/10 ) - small time crooks ( 7/10 ) - when harry met sally ( 10/10 ) - you've got mail ( 4/10 ) \n",
      "\n",
      "\u001b[40m\u001b[35m\u001b[22mA Random Negative Comment:\u001b[0m\u001b[34m\u001b[22m =============================================================================================\u001b[0m\n",
      "violence is bad . \n",
      "violence is ugly . \n",
      "violence breeds yet more violence . \n",
      "kids , don't try this at home . \n",
      "this weighty message isn't the only barrier to enjoying brother , but it's certainly one of the largest . \n",
      "written , directed by , and starring the infamous takeshi kitano ( kikujiro , sonatine ) brother is his first film made outside his familial japan , bringing the yakuza tradition to los angeles . \n",
      " ( yakuza translated for the average american is the japanese mafia . ) \n",
      "if you piss a \" family \" member off , or dishonor yourself in any way , the usual punishment is public display of self-mutilation , usually resulting in the loss of limbs . \n",
      "a definition of dishonor can be anything from making a stupid decision to leaving one family for another . \n",
      "it would be interesting to know more about where these and other customs come from . \n",
      "unfortunately the film doesn't give too much of an explanation , assuming its audience is aware of kitano's earlier work . \n",
      "there are several shots that focus specifically on detailed tattoos that spread across the entire back of the yakuza members , leading one to assume they would be symbolic of something , but you never know what . \n",
      "then there's a scene in which a man kills himself in front of a rival in exchange for that rival joining the family . \n",
      "granted , this is one of the best scenes in the movie , but it doesn't make a lot of sense . \n",
      "instead , the two hours are basically spent watching the following : people go out and shoot each other , talk about it for ten-plus minutes , then go out and do it again . \n",
      "the consistently repetitive discussion of territory during these moments involuntarily provokes yawning . \n",
      "there are also plot details thrown in for no identifiable purpose . \n",
      "all of the sudden yamamoto ( kitano ) has a girlfriend . \n",
      "he barely speaks to her , treats her like crap , and then sends her away . \n",
      "another missed opportunity , considering it is such a big deal for kitano to bring his magic to the united states , is the combination of cultures , which rely too heavily on overused stereotypes . \n",
      "though slow moving , brother does have good elements . \n",
      "the action scenes are well directed , clearly defined , and interesting to watch . \n",
      "some of the violence is more hinted at than shown , which produces the luscious squirm that one goes to see such films for . \n",
      "the actors would be more enticing if they had more to do . \n",
      "shirase's ( masaya kato ) loud , sarcastic coolness set against yamamoto's quietly threatening attitude is truly an entertaining combination . \n",
      "their moments together or apart steal the rest of the show . \n",
      "also to its credit , brother tackles the cause and effect of crime with realism . \n",
      "a life of crime is easy to get sucked into with the first reward of quick cash . \n",
      "sure people get rich , but they can also lose just as easily . \n",
      "it's a great moral , with a great cast , just not much substance to back it up . \n",
      "\n",
      "\u001b[34m\u001b[22m========================================================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# A Random Positive Comment:\n",
    "print(Back.BLACK + Fore.GREEN + Style.NORMAL + 'A Random Positive Comment:' +\n",
    "      Style.RESET_ALL + Fore.BLUE + Style.NORMAL + ' %s' % Line(120- len('A Random Positive Comment:') - 1) + Style.RESET_ALL)\n",
    "print(movie_reviews.raw(fileids = movie_reviews.fileids('pos') [np.random.randint(len(movie_reviews.fileids('pos')))]))\n",
    "# A Random Negative Comment:\n",
    "print(Back.BLACK + Fore.MAGENTA + Style.NORMAL + 'A Random Negative Comment:' +\n",
    "      Style.RESET_ALL + Fore.BLUE + Style.NORMAL + ' %s' % Line(120- len('A Random Negative Comment:') - 1) + Style.RESET_ALL)\n",
    "\n",
    "print(movie_reviews.raw(fileids = movie_reviews.fileids('neg') [np.random.randint(len(movie_reviews.fileids('neg')))]))\n",
    "print(Fore.BLUE + Style.NORMAL + '%s' % Line(120) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "\n",
    "We would like to determine whether a given comment is <font color='Green'><b>positive</b></font> or <font color='Red'><b>negative</b></font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "To start we would like to define a list of tuples in which each comment is tokenized into words and together with its category, positive or negative, form a tuple. A list of these tuples creates our base for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Documents = [(list(movie_reviews.words(fileid)), Category) # the tuple\n",
    "             for Category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(Category)]\n",
    "# Shuffle Document\n",
    "random.shuffle(Documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using nltk's [FeqDis](http://www.nltk.org/api/nltk.html?highlight=freqdist), we can identify words that often appear consecutively in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can consider the top 2000 words from the above list as **Featured Words**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Featured_Words = list(All_Words)[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define a **feature extractor** function that checks whether each of these words is present in a given document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Document_Features(Doc):\n",
    "    # converting the Doc into a set\n",
    "    Doc_words = set(Doc)\n",
    "    # Creating an empty set of features\n",
    "    features = {}\n",
    "    # a loop over featured words\n",
    "    for word in Featured_Words:\n",
    "        features['contains({})'.format(word)] = (word in Doc_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, for a randomly given <font color='Green'><b>positive</b></font> comment, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[22mThe first ten entries of this dictionary:\u001b[0m\n",
      "contains(plot): False \n",
      "contains(:): True \n",
      "contains(two): True \n",
      "contains(teen): False \n",
      "contains(couples): False \n",
      "contains(go): True \n",
      "contains(to): True \n",
      "contains(a): True \n",
      "contains(church): False \n",
      "contains(party): False \n"
     ]
    }
   ],
   "source": [
    "Temp = movie_reviews.words(fileids = movie_reviews.fileids('pos') [np.random.randint(len(movie_reviews.fileids('pos')))])\n",
    "Temp = Document_Features(Temp)\n",
    "print(Fore.BLUE + Style.NORMAL + 'The first ten entries of this dictionary:' + Style.RESET_ALL)\n",
    "for x in list(Temp)[0:10]:\n",
    "    print (\"{}: {} \".format(x,  Temp[x]))\n",
    "#\n",
    "del Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sake of modeling, we can split the train and test sets with 90% and 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_191b01a4_9c6f_11ea_b700_50e08586bf81\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Train Set</th>        <th class=\"col_heading level0 col1\" >Test Set</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_191b01a4_9c6f_11ea_b700_50e08586bf81level0_row0\" class=\"row_heading level0 row0\" >Size</th>\n",
       "                        <td id=\"T_191b01a4_9c6f_11ea_b700_50e08586bf81row0_col0\" class=\"data row0 col0\" >1800</td>\n",
       "                        <td id=\"T_191b01a4_9c6f_11ea_b700_50e08586bf81row0_col1\" class=\"data row0 col1\" >200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_191b01a4_9c6f_11ea_b700_50e08586bf81level0_row1\" class=\"row_heading level0 row1\" >Percentage</th>\n",
       "                        <td id=\"T_191b01a4_9c6f_11ea_b700_50e08586bf81row1_col0\" class=\"data row1 col0\" >90</td>\n",
       "                        <td id=\"T_191b01a4_9c6f_11ea_b700_50e08586bf81row1_col1\" class=\"data row1 col1\" >10</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e296f21308>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Feature_Sets = [(Document_Features(d), c) for (d,c) in Documents]\n",
    "Split = int(0.1 * len(Feature_Sets))\n",
    "\n",
    "Train_Set, Test_Set = Feature_Sets[Split:], Feature_Sets[:Split]\n",
    "\n",
    "Temp = pd.DataFrame({'Train Set': [len(Train_Set)], 'Test Set': [len(Test_Set)]}, index = ['Size']).T\n",
    "Temp['Percentage'] = np.round(100* Temp['Size'].values/Temp['Size'].values.sum(), 2)\n",
    "display(Temp.T.style.set_precision(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: Naive Bayes Classifier\n",
    "\n",
    "A [naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) is an algorithm that uses Bayes' theorem to classify objects. To learn more about text classification using naive Bayes classifier see this [link](https://web.stanford.edu/~jurafsky/slp3/slides/7_NB.pdf). Now, we can implement this using [nltk.classify.naivebayes](https://www.nltk.org/_modules/nltk/classify/naivebayes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Set</th>\n",
       "      <th>Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>88.67</td>\n",
       "      <td>79.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Train Set  Test Set\n",
       "Accuracy      88.67      79.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NBC = nltk.NaiveBayesClassifier.train(Train_Set)\n",
    "\n",
    "display(pd.DataFrame({'Train Set': [100*nltk.classify.util.accuracy(NBC, Train_Set)],\n",
    "              'Test Set': [100*nltk.classify.util.accuracy(NBC, Test_Set)]}, index = ['Accuracy']).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **show_most_informative_features()** to find out which features the classifier found to be most informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(turkey) = True              neg : pos    =     11.9 : 1.0\n",
      "    contains(schumacher) = True              neg : pos    =     11.8 : 1.0\n",
      "     contains(atrocious) = True              neg : pos    =     10.4 : 1.0\n",
      " contains(unimaginative) = True              neg : pos    =      7.8 : 1.0\n",
      "      contains(explores) = True              pos : neg    =      6.9 : 1.0\n",
      "        contains(suvari) = True              neg : pos    =      6.4 : 1.0\n",
      "          contains(mena) = True              neg : pos    =      6.4 : 1.0\n",
      "       contains(singers) = True              pos : neg    =      6.3 : 1.0\n",
      "       contains(wounded) = True              pos : neg    =      5.7 : 1.0\n",
      "        contains(shoddy) = True              neg : pos    =      5.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NBC.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "For a randomly given <font color='Green'><b>positive</b></font> comment, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32m\u001b[22mA Random Positive Comment:\u001b[0m\u001b[34m\u001b[22m =============================================================================================\u001b[0m\n",
      "the party is one of those classic slapstick comedies that will leave you , at times , cracking up . \n",
      "the film takes place , for the most part , in real-time during an exclusive evening party that is attended only by the biggest names in hollywood . \n",
      "hrundi v . bakshi , played very well by peter sellers , is a struggling actor who just came to america from his homeland , india . \n",
      "hrundi tries out his acting talents , but it seems that he just isn't cut out for the job . \n",
      "on the set of his current film that he stars in , hrundi seems to make everything go for the worse . \n",
      "during the filming of this movie set in the 1800's , hrundi manages to annoy the director ( herbert ellis ) in any way he can . \n",
      "this includes a pitiful acting job in many scenes , wearing an underwater watch in one scene , and accidentally detonating a massive set . \n",
      "many of the hollywood producers and big names want hrundi out of the business forever . \n",
      "and when the director makes a personal phone call to mr . clutterbuck ( j . \n",
      "edward mckinley ) pleading for hrundi's ejection from hollywood , everything is pretty much over for hrundi . \n",
      "clutterbuck writes his name down on a piece of paper to insure that hrundi will never again work in hollywood . \n",
      "but when this piece of paper turns out to be the guest list for clutterbuck's exclusive party , hrundi is invited , and certain chaos is bound to occur . \n",
      "of course , as predicted , hrundi causes lots of trouble . \n",
      "each scene in which hrundi encounters a situation , usually one that he can't handle , is almost always very humorous . \n",
      "and each scene with hrundi and the drunken waiter , who is alone hilarious , adds to the comedy in a great way . \n",
      "the party can be compared to many other films of it's type , specifically the trio of naked gun movies and the airplane movies , but the party is a delightful movie that incorporates very well played out comedy into believable situations . \n",
      "it also includes a number of memorable scenes ( can anyone say \" birdy num-num \" ? ) . \n",
      "if you're in the mood for fun and enjoyable slapstick comedy , check out the party . \n",
      "it's not going to be one of your all-time favorites , but if you enjoy this type of humor , you'll enjoy the party . \n",
      "\n",
      "\u001b[40m\u001b[36m\u001b[22mPredictions:\u001b[0m\u001b[34m\u001b[22m ===========================================================================================================\u001b[0m\n",
      "\u001b[42m\u001b[30m\u001b[22mA Positive Comment\n"
     ]
    }
   ],
   "source": [
    "# A Random Positive Comment:\n",
    "print(Back.BLACK + Fore.GREEN + Style.NORMAL + 'A Random Positive Comment:' +\n",
    "      Style.RESET_ALL + Fore.BLUE + Style.NORMAL + ' %s' % Line(120- len('A Random Positive Comment:') - 1) + Style.RESET_ALL)\n",
    "Temp = np.random.randint(len(movie_reviews.fileids('pos')))\n",
    "print(movie_reviews.raw(fileids = movie_reviews.fileids('pos') [Temp]))\n",
    "Temp = movie_reviews.words(fileids = movie_reviews.fileids('pos') [Temp])\n",
    "print(Back.BLACK + Fore.CYAN + Style.NORMAL + 'Predictions:' +\n",
    "      Style.RESET_ALL + Fore.BLUE + Style.NORMAL + ' %s' % Line(120- len('Predictions:') - 1) + Style.RESET_ALL)\n",
    "Temp = NBC.classify(Document_Features(Temp))\n",
    "if Temp == 'pos':\n",
    "    print(Back.GREEN + Fore.BLACK + Style.NORMAL + 'A Positive Comment')\n",
    "else:\n",
    "    print(Back.RED + Fore.BLACK + Style.NORMAL + 'A Negative Comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, for a randomly given <font color='Red'><b>negative</b></font> comment, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32m\u001b[22mA Random Negative Comment:\u001b[0m\u001b[34m\u001b[22m =============================================================================================\u001b[0m\n",
      "what are the warning signs of a * terrible * movie ? \n",
      "making it's debut at the dollar theater ? \n",
      "locally , chairman of the board did just that . \n",
      "having the annoying prop comic scott thompson ( better known as carrot top ) in the lead role ? \n",
      "chairman of the board , once again . \n",
      "how about an overly exhausted , paper thin plot approached with utter incompetence ? \n",
      "did somebody say chairman of the board ? \n",
      "that's right , carrot top's long dreaded major motion picture debut ( at least for a starring role ) is poking up in a handful of theaters across the country . \n",
      "chairman of the board stars the obnoxious , wannabe-zany king of redheaded standup comics as a lazy but creative , inventive but uneventful generation x- er named edison . \n",
      "living with a pair of surfer dudes in a small , rented house , edison bounces from job to job , always squandering away the money on his eccentric ( to say the least ) inventions and ignoring crucial responsibilities such as rent . \n",
      "this has the crabby landlady , ms . krubavitch ( estelle harris , best known as george constanza's mother on \" seinfeld \" ) , threatening an eviction if past due expenses aren't furnished post haste . \n",
      "as luck would have it , edison soon meets armand mcmillan ( jack warden ) , an old surfer dude who just so happens to be president of the multi-million dollar mcmillan industries . \n",
      "sharing a passion for more than just riding waves , armand is deeply impacted by the young inventor's notebook of dreams and ideas , and when the old man dies soon afterward , edison learns he is named a benefactor in armand's will . \n",
      "predictably , edison acquires the entire corporation and has to maintain productivity with absolutely no knowledge of the business world . \n",
      "predictably , there is a bitter nephew ( larry miller ) whose lesser inheritance fuels resentment that will lead to an elaborate sabotage plot . \n",
      "predictably , there is an attractive employee ( courtney thorne-smith ) whose initial repulsion will transform into love for our doofy protagonist . \n",
      "predictably , the man who knows nothing will fight against the odds and give the company it's most profitable and successful turnaround ever , all because he ran things by common sense and not greed . \n",
      "it's as though writers turi meyer , al septien , and alex zamm ( meyer and septien also wrote leprechaun 2 together ! ) \n",
      "pulled a plot out of a hat and worked carrot top into it . \n",
      "the jokes , the \" surprises \" , the developments - all of them run such a predictable path , it may only be carrot top's signature brazen red hairdo that sets this one apart from the myriad of similar films . \n",
      "a movie this bad speaks for itself . \n",
      "what's left to say when every element the movie possesses is a shameful retread of movies past ? \n",
      "the script is 100% recycled , the direction is hokey , and the acting is absolutely horrible . \n",
      "it is only thorne-smith who seems to take her job seriously , an accomplishment which surely deserves the medal of honor . \n",
      "she certainly went beyond the call of duty - she has to kiss carrot top ! ! ! ! ! ! \n",
      " ( barf bag , please ! ) \n",
      "movies like this give the audience nothing to do but ponder just how many synonyms for \" bad \" there really are . \n",
      "chairman of the board , without a doubt , deserves each and every one . \n",
      "the only way this won't end up on everybody's \" bottom ten of the year \" list , is if they were lucky enough never to have seen it . \n",
      "just because you can't miss his outlandish fiery mane , don't skimp on avoiding this abhorrent feature . \n",
      "\n",
      "\u001b[40m\u001b[36m\u001b[22mPredictions:\u001b[0m\u001b[34m\u001b[22m ===========================================================================================================\u001b[0m\n",
      "\u001b[41m\u001b[30m\u001b[22mA Negative Comment\n"
     ]
    }
   ],
   "source": [
    "# A Random Positive Comment:\n",
    "print(Back.BLACK + Fore.GREEN + Style.NORMAL + 'A Random Negative Comment:' +\n",
    "      Style.RESET_ALL + Fore.BLUE + Style.NORMAL + ' %s' % Line(120- len('A Random Negative Comment:') - 1) + Style.RESET_ALL)\n",
    "Temp = np.random.randint(len(movie_reviews.fileids('neg')))\n",
    "print(movie_reviews.raw(fileids = movie_reviews.fileids('neg') [Temp]))\n",
    "Temp = movie_reviews.words(fileids = movie_reviews.fileids('neg') [Temp])\n",
    "print(Back.BLACK + Fore.CYAN + Style.NORMAL + 'Predictions:' +\n",
    "      Style.RESET_ALL + Fore.BLUE + Style.NORMAL + ' %s' % Line(120- len('Predictions:') - 1) + Style.RESET_ALL)\n",
    "Temp = NBC.classify(Document_Features(Temp))\n",
    "if Temp == 'pos':\n",
    "    print(Back.GREEN + Fore.BLACK + Style.NORMAL + 'A Positive Comment')\n",
    "else:\n",
    "    print(Back.RED + Fore.BLACK + Style.NORMAL + 'A Negative Comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Refrences\n",
    "\n",
    "* \"Natural Language Toolkit\". [www.nltk.org](https://www.nltk.org/).\n",
    "* Bird, S., Klein, E., and Loper E., \"Natural Language Processing with Python\". [Chapter 6: Learning to Classify Text](https://www.nltk.org/book/ch06.html)\n",
    "* \"Movie Review Data\", [www.cs.cornell.edu/people/pabo/movie-review-data](http://www.cs.cornell.edu/people/pabo/movie-review-data/)\n",
    "* Pang B., Lee L., and Vaithyanathan S., \"[Thumbs up? Sentiment Classification using Machine Learning Techniques](http://www.cs.cornell.edu/home/llee/papers/sentiment.home.html)\", Proceedings of EMNLP 2002.\n",
    "* Pang B., and Lee L., \"A Sentimental Education: [Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts](http://www.cs.cornell.edu/home/llee/papers/cutsent.home.html)\", Proceedings of ACL 2004.\n",
    "* Pang B., and Lee L.,  \"Seeing stars: [Exploiting class relationships for sentiment categorization with respect to rating scales](http://www.cs.cornell.edu/home/llee/papers/pang-lee-stars.home.html)\", Proceedings of ACL 2005.\n",
    "*  Jan Strunk, Punkt Tokenizer Models. [nltk.org/nltk_data](http://www.nltk.org/nltk_data/).\n",
    "* Jurafsky, D., and Martin, M. H. (2019). \"[Speech and Language Processing (3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/)\".\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
